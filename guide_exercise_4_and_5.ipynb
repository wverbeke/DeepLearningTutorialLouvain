{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is the model solution to exercises 1, 2 and 3, the solution of which is needed to start exercise 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "\n",
    "#open files\n",
    "signal_f = uproot.open('GluGluHToWWTo2L2Nu_M125.root')\n",
    "bkg_f = ( uproot.open('DYJetsToLL_M-10to50-LO.root'), uproot.open('DYJetsToLL_M-50-LO.root') )\n",
    "\n",
    "#open trees\n",
    "sig_tree = signal_f[ 'Events' ]\n",
    "bkg_trees = [ f['Events'] for f in bkg_f ]\n",
    "\n",
    "#list of input variables\n",
    "input_variables = [ 'ptll', 'mth', 'jetpt1_cut', 'uperp', 'upara', 'PfMetDivSumMet', 'recoil', 'mpmet', 'mtw1', 'mtw2', 'PuppiMET_pt', 'MET_pt', 'TkMET_pt', 'projtkmet', 'projpfmet', 'dphilljet_cut', 'dphijet1met_cut', 'dphillmet', 'dphilmet1', 'dphilmet2', 'jetpt2_cut', 'dphijet2met_cut', 'dphilljetjet_cut', 'dphijjmet_cut', 'ptTOT_cut', 'mTOT_cut', 'PV_npvsGood' ]\n",
    "\n",
    "#function to convert dictionary of arrays to 2D array\n",
    "def arrayDictTo2DArray( array_dict ):\n",
    "    ret_array = None\n",
    "    for key in array_dict:\n",
    "        if ret_array is None:\n",
    "            ret_array = array_dict[key]\n",
    "            ret_array = np.expand_dims( ret_array, 1 )\n",
    "        else :\n",
    "            new_array = np.expand_dims( array_dict[key], 1 )\n",
    "            ret_array = np.concatenate( [ret_array, new_array], axis = 1 )\n",
    "    return ret_array\n",
    "\n",
    "\n",
    "#function to normalize array of inputs ( center distribution at 0 and give them unit variance )\n",
    "def normalizeInputArray( array2D ):\n",
    "\n",
    "    #calculate mean along event axis, and expand dimensions of array so that it can be subtracted from previous array\n",
    "    array2D -= np.expand_dims( np.mean( array2D, axis = 1 ), axis = 1 )\n",
    "    array2D /= np.expand_dims( np.std( array2D, axis = 1 ), axis = 1 )\n",
    "    return array2D\n",
    "\n",
    "#build signal and background arrays\n",
    "signal_data = normalizeInputArray( arrayDictTo2DArray( sig_tree.arrays( input_variables ) ) )\n",
    "background_data_list = [ normalizeInputArray( arrayDictTo2DArray(tree.arrays( input_variables ) ) ) for tree in bkg_trees ]\n",
    "\n",
    "#merge arrays for two different backgrounds\n",
    "background_data = np.concatenate( background_data_list, axis = 0 )\n",
    "\n",
    "\n",
    "#list of variables representing weights \n",
    "weight_variables = [ 'XSWeight', 'SFweight2l', 'LepSF2l__ele_mvaFall17V1Iso_WP90__mu_cut_Tight_HWWW', 'LepCut2l__ele_mvaFall17V1Iso_WP90__mu_cut_Tight_HWWW', 'GenLepMatch2l', 'METFilter_MC' ]\n",
    "\n",
    "#function to build the total weight array for one tree \n",
    "def getWeightArray( tree, weight_variables ):\n",
    "    weight_array = None\n",
    "    for key in weight_variables:\n",
    "        if weight_array is None:\n",
    "            weight_array = tree.array( key )\n",
    "        else :\n",
    "            weight_array *= tree.array( key )\n",
    "    return weight_array\n",
    "\n",
    "#read signal and background weights\n",
    "signal_weights = getWeightArray( sig_tree, weight_variables )\n",
    "bkg_weights = np.concatenate( [ getWeightArray( bkg_tree, weight_variables ) for bkg_tree in bkg_trees ], axis = 0 )\n",
    "\n",
    "#avoid large numerical scales of weights\n",
    "signal_weights /= np.mean( signal_weights )\n",
    "bkg_weights /= np.mean( bkg_weights )\n",
    "\n",
    "#define arrays with labels for signal and background events\n",
    "#these are what the neural network will try to predict\n",
    "signal_labels = np.ones( len( signal_weights ) )\n",
    "bkg_labels = np.zeros( len( bkg_weights ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 4: Now ramdonly shuffle the input data, weights and labels simultaneously for both signal and background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 4: Now split all signal and background information into training validation and test sets. Do this by writing a function that splits an array given a validation and test fraction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 5: Now merge signal and background arrays for the training, validation and test sets, and randomize each of them after merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 5: You are now done reading in the data! Now we will feed it into a (currently VERY VERY BAD) neural network, train it and evaluate its performance. Just fill in the names of your datasets where 'train_data', etc are written below and run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have the datasets we need for training a neural network!\n",
    "#Given below is a ( currently VERY VERY BAD!!!) neural network that will be trained\n",
    "\n",
    "#keras modules\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add( layers.Dense(64, activation='linear' ) )\n",
    "network.add( layers.Dense(1, activation='sigmoid' ) )\n",
    "\n",
    "#to use auc as a keras metric \n",
    "import tensorflow as tf\n",
    "\n",
    "network.compile(\n",
    "    optimizer=optimizers.Nadam(),\n",
    "    loss=losses.binary_crossentropy,\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC()]\n",
    ")\n",
    "\n",
    "history = network.fit(\n",
    "    train_data,\n",
    "    train_labels,\n",
    "    sample_weight =train_weights,\n",
    "    epochs=10,\n",
    "    batch_size=1024,\n",
    "    validation_data=( val_data, val_labels, val_weights ),\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "train_output_signal = network.predict( signal_data_train )\n",
    "train_output_bkg = network.predict( bkg_data_train )\n",
    "val_output_signal = network.predict( signal_data_val )\n",
    "val_output_bkg = network.predict( bkg_data_val )\n",
    "\n",
    "\n",
    "#plot ROC curve and compute AUC\n",
    "from diagnosticPlotting import plotKerasMetricComparison, plotROC, computeROC, plotOutputShapeComparison, areaUnderCurve\n",
    "\n",
    "sig_eff, bkg_eff = computeROC( val_output_signal, signal_weights_val, val_output_bkg, bkg_weights_val, num_points = 10000 )\n",
    "\n",
    "plotROC( sig_eff, bkg_eff, 'roc' )\n",
    "print('######################################' )\n",
    "roc_integral = areaUnderCurve( sig_eff, bkg_eff )\n",
    "print( 'ROC INTEGRAL = {}'.format( roc_integral ) )\n",
    "print('######################################' )\n",
    "\n",
    "#plot output shape for training and validation sets\n",
    "plotOutputShapeComparison( train_output_signal, signal_weights_train, train_output_bkg, bkg_weights_train,\n",
    "    val_output_signal, signal_weights_val,\n",
    "    val_output_bkg, bkg_weights_val,\n",
    "    'model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
